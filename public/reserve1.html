<!DOCTYPE html>
<html lang=en>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
<script src="https://unpkg.com/face-api.js@0.22.2/dist/face-api.min.js"></script>
<style>
  @keyframes slideUpFade{
from{
transform: translateY(20px);
opacity: 0;
}
to{
transform: translateY(0);
opacity: 1;
}
  }
body {
background-color: #ff9999;
display: flex;
align-items: center;
flex-direction: column;
}
#camera {
border: none;
border-radius: 10px;
box-shadow: 0 0 10px rgba(0,0,0,0.5);
display: block;
width: 300px;
height: 400px;
object-fit: cover;
padding: 5px;
  animation: slideUpFade 0.5s ease-out;
}
#picdiv{
border: 2px solid white;
border-radius: 10px;
box-shadow: 0 0 10px rgba(0,0,0,0.5);
display: block;
width: 300px;
height: 400px;
object-fit: cover;

  animation: slideUpFade 0.5s ease-out;
}
#picdiv > canvas,#previewcanvas {
padding: 5px;
border: none;
border-radius: 10px;
}
#btn,#btn1,#btn2,#btn3,#btn4{
background-color: FloralWhite;
  border-radius: 10px;
  border: none;
  padding: 10px;
  animation: slideUpFade 0.5s ease-out;
}
#btn:hover,#btn1:hover,#btn2:hover,#btn3:hover,#btn4:hover{
background-color: red;
transform: scale(1.03);
transition: all 0.2s ease-in-out;
}
#overlay,#newoverlay{
  position: fixed;
  top: 0;
  left: 0;
  width: 100vw;
  height: 100vh;
  visibility: hidden;
     display: flex;
     flex-direction: column;
    align-items: center;
    justify-content: center;
    z-index: 1001;
    backdrop-filter: blur(8px);
    background-color: rgba(0,0,0,0.5);
    opacity: 0;
    transition: opacity 0.3s ease;
  }
  #newoverlay div {
    background-color: white;
    padding: 20px 30px;
    border-radius: 10px;
    font-size: 1.5em;
    text-align: center;
    color: black;
    box-shadow: 0 0 15px rgba(0,0,0,0.5);
}
  #overlay.show,#newoverlay.show{
    visibility: visible;
    opacity: 1;
  }
  #previewcanvas{
    max-height: 90vh;
    max-width: 90vw;
    height: auto;
    width: auto;
    z-index: 1002;
    border-radius: 10px;
    border: none;
  }
</style>
    <title>Camera Access</title>
</head>
<body>
  <div id="main" style="display:none;">
  <div id="newoverlay">
  <div id="message">
  <p id="p">Capturing image...</p>
  </div>
  <button id="btn4" style="z-index: 1002;">cancel</button>
  </div>
    <div id="overlay">
      <canvas id="previewcanvas"></canvas>
      <button id="btn3" style="z-index: 1002;">close</button>
    </div>
    <h2>Enter a picture of your face </h2>
    <div style="position:relative; width:300px; height:400px;">
    <video id="camera" width="300" height="400" autoplay></video>
    <canvas id="overlaycanvas" style="position:absolute;top:0;left:0;width:300px;height:400px;"></canvas>
    </div>
    <div style="padding: 10px;">
    <button id="btn" style="display:none;">Capture manually</button>
    <button id="btn1" style="display:none;">Clear</button>
    </div>
    <div id="picdiv" style="display:none;">
    <canvas id="snapshot" width="300" height="400" title="preview image"></canvas>
      <button id="btn2" style="display:none;">run scanning</button>
    </div>
  </div>
    <script>
        const video = document.getElementById('camera');
        const canvas = document.getElementById('snapshot');
        const previewcanvas = document.getElementById('previewcanvas');
        const context = canvas.getContext('2d');
        const copiedContext = previewcanvas.getContext('2d');
        const main = document.getElementById('main');
        const savebtn = document.getElementById('btn2');
      const clearbtn =  document.getElementById('btn1');
      const capturebtn = document.getElementById('btn');
      const overlay = document.getElementById("overlay");
      const closebtn = document.getElementById('btn3');
      const overlaycanvas = document.getElementById('overlaycanvas');
      const overlayContext = overlaycanvas.getContext('2d');
      const newoverlay = document.getElementById('newoverlay');
      const cancelbtn = document.getElementById('btn4');
      const picdiv = document.getElementById('picdiv');
      let canceled = false;
      //load face detection model
      let model;
      let interval1 = null;
      savebtn_clone = savebtn.cloneNode(true);
      async function loadFaceAPIModels() {
  try {
    console.log('Starting to load Face-API models...');

    // Try loading SSD Mobilenet instead of TinyFaceDetector
    try {
      await faceapi.nets.ssdMobilenetv1.loadFromUri('./models/');
      console.log('SSD Mobilenet loaded successfully');
    } catch (ssdError) {
      console.error('FAILED to load SSD Mobilenet:', ssdError);
      // Fall back to trying TinyFaceDetector
    }
    try {
        await faceapi.nets.tinyFaceDetector.loadFromUri('./models/');
        console.log('TinyFaceDetector loaded successfully (fallback)');
      } catch (tinyError) {
        console.error('FAILED to load TinyFaceDetector too:', tinyError);
        throw new Error('No face detection models could be loaded');
      }

    await faceapi.nets.faceRecognitionNet.loadFromUri('./models/');
    console.log('FaceRecognitionNet loaded successfully');

    await faceapi.nets.faceLandmark68Net.loadFromUri('./models/');
    console.log('FaceLandmark68Net loaded successfully');

    console.log('Face-api model loading completed');

  } catch (error) {
    console.error('Error loading Face-API models:', error);
    throw error;
  }
}
      
      async function loadImageFromDataURL(dataURL) {
    return new Promise((resolve, reject) => {
        const img = new Image();
        img.crossOrigin = "anonymous";
        img.onload = () => resolve(img);
        img.onerror = reject;
        img.src = dataURL;
    });
}
      function imageToCanvas(img) {
  const offCanvas = document.createElement('canvas');
  offCanvas.width = img.width;
  offCanvas.height = img.height;
  const ctx = offCanvas.getContext('2d');
  ctx.drawImage(img, 0, 0, img.width, img.height);
  return offCanvas;
}
async function compareFaces() {
    try {
        const storedDataURL = localStorage.getItem('imageData');
        if (!storedDataURL) {
            alert('ðŸŒ¸ No stored image found in session storage');
            return;
        }

        const currentCanvas = document.getElementById('snapshot');
        if (!currentCanvas || currentCanvas.width === 0 || currentCanvas.height === 0) {
            alert('ðŸŒ¸ Current snapshot is empty');
            return;
        }

        // Load stored image
        const storedImage = await loadImageFromDataURL(storedDataURL);

        // Detect faces and compute descriptors
        const [storedDetection, currentDetection] = await Promise.all([
            faceapi.detectSingleFace(storedImage).withFaceLandmarks().withFaceDescriptor(),
            faceapi.detectSingleFace(currentCanvas).withFaceLandmarks().withFaceDescriptor()
        ]);

        if (!storedDetection) {
            alert('ðŸŒ¸ No face detected in stored image');
            return;
        }

        if (!currentDetection) {
            alert('ðŸŒ¸ No face detected in current image');
            return;
        }

        const distance = faceapi.euclideanDistance(
            storedDetection.descriptor,
            currentDetection.descriptor
        );

        const threshold = 0.6;

        if (distance < threshold) {
            alert(`âœ… Face Match! Similarity: ${(1 - distance).toFixed(2)} (Distance: ${distance.toFixed(3)})`);
        } else {
            alert(`âŒ Faces do not match.\nSimilarity: ${(1 - distance).toFixed(2)} (Distance: ${distance.toFixed(3)})`);
        }

    } catch (err) {
        console.error('ðŸŒ§ï¸ Matching failed:', err);
        alert('ðŸŒ§ï¸ Error occurred during face matching. Check console for details.');
    }
}      let detectionPaused = false;
      let stopwork = false;
function showCapturedFace(start, area) {
    if (detectionPaused || canceled) return;  // Skip capturing forever if canceled

    // Pause face detection for the capturing animation
    detectionPaused = true;
    newoverlay.classList.add('show');
    void newoverlay.offsetWidth;

    setTimeout(() => {
    if(canceled) return;
        newoverlay.classList.remove('show');
        savebtn_clone.style.display = 'inline-block';
        overlay.appendChild(savebtn_clone);
        overlay.classList.add('show');
        previewcanvas.width = area.width;
        previewcanvas.height = area.height;
        copiedContext.clearRect(0, 0, previewcanvas.width, previewcanvas.height);
        copiedContext.filter = 'contrast(200%)';
        copiedContext.drawImage(
            video,
            start.x,start.y,area.width,area.height,
            0, 0, previewcanvas.width, previewcanvas.height
        );
    }, 3000);
}
let interval = null;
      // Request camera access
        navigator.mediaDevices.getUserMedia({ video: true })
            .then(async (stream) => {
                await loadFaceAPIModels();
                video.srcObject = stream;
                main.style.display = "block";
                video.addEventListener("loadeddata", () => {
                overlaycanvas.width = video.videoWidth;
                overlaycanvas.height = video.videoHeight;
             interval =  setInterval(async () =>{
                overlayContext.clearRect(0, 0, overlaycanvas.width, overlaycanvas.height);
             const livePredictions = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
                if(livePredictions.length > 0){
                livePredictions.forEach(pred => {
                const box = pred.box;
                overlayContext.strokeStyle = "red";
                overlayContext.lineWidth = 3;
                overlayContext.strokeRect(box.x, box.y, box.width, box.height);
                if(!canceled&&!detectionPaused){
                showCapturedFace({x: box.x, y: box.y},{width: box.width, height: box.height});
                }
                });
                }
                },100);
                });
            })
            .catch(err => {
                console.error('Error accessing camera:', err);
                alert('Please allow camera access!');

            });

        capturebtn.addEventListener("click",async () => {
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
          const tensors = false;
          const prediction = await model.estimateFaces(canvas,tensors);
          if(prediction.length > 0){
            alert("a face was detected");
          }
          else{
            alert("no face detected");
          }
            savebtn.style.display = "inline-block";
        });
        clearbtn.addEventListener("click",() => {
           context.clearRect( 0, 0, canvas.width, canvas.height);
          savebtn.style.display = "none";
        });
        savebtn.addEventListener("click", async () => {
        await compareFaces();
        });
         savebtn_clone.addEventListener("click",async () => {
         await compareFaces();
        });
      canvas.addEventListener("click", () => {
          overlay.classList.add('show');
          copiedContext.drawImage(canvas,0,0,previewcanvas.width, previewcanvas.height);
      });
      closebtn.addEventListener("click", () => {
         overlay.classList.remove('show');
         savebtn_clone.style.display = 'none';
         detectionPaused = false;
      });
      cancelbtn.addEventListener("click", () => {
      newoverlay.classList.remove('show');
      canceled = true;
        capturebtn.style.display = "inline-block";
        clearbtn.style.display = "inline-block";
        picdiv.style.display = "inline-block";
      clearInterval(interval1);
      });
    </script>
</body>
</html>
