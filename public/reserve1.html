<!DOCTYPE html>
<html lang=en>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script  src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
<script src="https://unpkg.com/face-api.js@0.22.2/dist/face-api.min.js"></script>
<style>
  @keyframes slideUpFade{
from{
transform: translateY(20px);
opacity: 0;
}
to{
transform: translateY(0);
opacity: 1;
}
  }
body {
background-color: #ff9999;
display: flex;
align-items: center;
flex-direction: column;
}
#camera {
border: none;
border-radius: 10px;
box-shadow: 0 0 10px rgba(0,0,0,0.5);
display: block;
width: 300px;
height: 400px;
object-fit: cover;
padding: 5px;
  animation: slideUpFade 0.5s ease-out;
}
#picdiv{
border: 2px solid white;
border-radius: 10px;
box-shadow: 0 0 10px rgba(0,0,0,0.5);
display: block;
width: 300px;
height: 400px;
object-fit: cover;

  animation: slideUpFade 0.5s ease-out;
}
#picdiv > canvas,#previewcanvas {
padding: 5px;
border: none;
border-radius: 10px;
}
#btn,#btn1,#btn2,#btn3,#btn4{
background-color: FloralWhite;
  border-radius: 10px;
  border: none;
  padding: 10px;
  animation: slideUpFade 0.5s ease-out;
}
#btn:hover,#btn1:hover,#btn2:hover,#btn3:hover,#btn4:hover{
background-color: red;
transform: scale(1.03);
transition: all 0.2s ease-in-out;
}
#overlay,#newoverlay{
  position: fixed;
  top: 0;
  left: 0;
  width: 100vw;
  height: 100vh;
  visibility: hidden;
     display: flex;
     flex-direction: column;
    align-items: center;
    justify-content: center;
    z-index: 1001;
    backdrop-filter: blur(8px);
    background-color: rgba(0,0,0,0.5);
    opacity: 0;
    transition: opacity 0.3s ease;
  }
  #newoverlay div {
    background-color: white;
    padding: 20px 30px;
    border-radius: 10px;
    font-size: 1.5em;
    text-align: center;
    color: black;
    box-shadow: 0 0 15px rgba(0,0,0,0.5);
}
  #overlay.show,#newoverlay.show{
    visibility: visible;
    opacity: 1;
  }
  #previewcanvas{
    max-height: 90vh;
    max-width: 90vw;
    height: auto;
    width: auto;
    z-index: 1002;
    border-radius: 10px;
    border: none;
  }
</style>
    <title>Camera Access</title>
</head>
<body>
  <div id="main" style="display:none;">
  <div id="newoverlay">
  <div id="message">
  <p id="p">Capturing image...</p>
  </div>
  <button id="btn4" style="z-index: 1002;">cancel</button>
  </div>
    <div id="overlay">
      <canvas id="previewcanvas"></canvas>
      <button id="btn3" style="z-index: 1002;">close</button>
    </div>
    <h2>Enter a picture of your face </h2>
    <div style="position:relative; width:300px; height:400px;">
    <video id="camera" width="300" height="400" autoplay></video>
    <canvas id="overlaycanvas" style="position:absolute;top:0;left:0;width:300px;height:400px;"></canvas>
    </div>
    <div style="padding: 10px;">
    <button id="btn" style="display:none;">Capture manually</button>
    <button id="btn1" style="display:none;">Clear</button>
    </div>
    <div id="picdiv" style="display:none;">
    <canvas id="snapshot" width="300" height="400" title="preview image"></canvas>
      <button id="btn2" style="display:none;">run scanning</button>
    </div>
  </div>
    <script>
        const video = document.getElementById('camera');
        const canvas = document.getElementById('snapshot');
        const previewcanvas = document.getElementById('previewcanvas');
        const context = canvas.getContext('2d');
        const copiedContext = previewcanvas.getContext('2d');
        const main = document.getElementById('main');
        const savebtn = document.getElementById('btn2');
      const clearbtn =  document.getElementById('btn1');
      const capturebtn = document.getElementById('btn');
      const overlay = document.getElementById("overlay");
      const closebtn = document.getElementById('btn3');
      const overlaycanvas = document.getElementById('overlaycanvas');
      const overlayContext = overlaycanvas.getContext('2d');
      const newoverlay = document.getElementById('newoverlay');
      const cancelbtn = document.getElementById('btn4');
      const picdiv = document.getElementById('picdiv');
      let canceled = false;
      //load face detection model
      let model;
      let interval1 = null;
      savebtn_clone = savebtn.cloneNode(true);
      savebtn.disabled = true;
      savebtn_clone.disabled = true;
      async function loadFaceAPIModels() {
  try {
    console.log('Starting to load Face-API models...');

    // Try loading SSD Mobilenet instead of TinyFaceDetector
    try {
      await faceapi.nets.ssdMobilenetv1.loadFromUri('./models');
      console.log('SSD Mobilenet loaded successfully');
    } catch (ssdError) {
      console.error('FAILED to load SSD Mobilenet:', ssdError);
      // Fall back to trying TinyFaceDetector
      try {
        await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
        console.log('TinyFaceDetector loaded successfully (fallback)');
      } catch (tinyError) {
        console.error('FAILED to load TinyFaceDetector too:', tinyError);
        throw new Error('No face detection models could be loaded');
      }
    }

    await faceapi.nets.faceRecognitionNet.loadFromUri('./models');
    console.log('FaceRecognitionNet loaded successfully');

    await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
    console.log('FaceLandmark68Net loaded successfully');

    console.log('Face-api model loading completed');

  } catch (error) {
    console.error('Error loading Face-API models:', error);
    throw error;
  }
}
      async function loadModel(){
          model = await blazeface.load();
          console.log("face detection model loaded");
      }
      (async () => {await loadFaceAPIModels();
      savebtn.disabled = false;
      savebtn_clone.disabled = false;
      })();
      function loadFomDataURL(DataURL){
      return new Promise((resolve,reject) => {
      const img = new Image();
      img.onload = () => resolve(img);
      img.onerror = (err) => reject(img);
      img.src = DataURL;
      });
      }
      function imageToCanvas(img) {
  const offCanvas = document.createElement('canvas');
  offCanvas.width = img.width;
  offCanvas.height = img.height;
  const ctx = offCanvas.getContext('2d');
  ctx.drawImage(img, 0, 0, img.width, img.height);
  return offCanvas;
}
async function matchFaces(canvasEl) {
  try {
    console.log('Starting face matching...');

    if (!canvasEl || canvasEl.width === 0 || canvasEl.height === 0) {
      alert("Canvas is empty — nothing to compare.");
      return;
    }

    const storedDataURL = sessionStorage.getItem('imageData');
    if (!storedDataURL) {
      alert("No stored image found");
      return;
    }

    // Load stored image
    const storedImg = await loadFomDataURL(storedDataURL);
    const storedCanvas = imageToCanvas(storedImg);

    // Use the CORRECT options format for v0.22.2
    const options = new faceapi.SsdMobilenetv1Options({
      minConfidence: 0.5
    });

    console.log('Options:', options);
    console.log('Canvas dimensions:', canvasEl.width, canvasEl.height);
    console.log('Stored canvas dimensions:', storedCanvas.width, storedCanvas.height);

    // For v0.22.2, use this approach (NO method chaining)
    const newDetections = await faceapi.detectAllFaces(canvasEl, options);
    console.log('New detections:', newDetections);

    const storedDetections = await faceapi.detectAllFaces(storedCanvas, options);
    console.log('Stored detections:', storedDetections);

    if (storedDetections.length !== 1 || newDetections.length !== 1) {
      alert('Please ensure exactly one face in both images. Found: ' +
            storedDetections.length + ' vs ' + newDetections.length);
      return;
    }

    // Get landmarks and descriptors separately
    const newLandmarks = await faceapi.detectFaceLandmarks(canvasEl, newDetections);
    const newDescriptors = await faceapi.computeFaceDescriptors(canvasEl, newLandmarks);

    const storedLandmarks = await faceapi.detectFaceLandmarks(storedCanvas, storedDetections);
    const storedDescriptors = await faceapi.computeFaceDescriptors(storedCanvas, storedLandmarks);

    const distance = faceapi.euclideanDistance(storedDescriptors[0], newDescriptors[0]);
    const threshold = 0.6;

    console.log('Distance:', distance);

    if (distance < threshold) {
      alert(`Match found! Distance: ${distance.toFixed(3)}`);
    } else {
      alert(`No match… Distance: ${distance.toFixed(3)}`);
    }

  } catch (err) {
    console.error('matchFaces error:', err);
    alert('Face comparison error — see console for details.');
  }
}

      let detectionPaused = false;
      let stopwork = false;
function showCapturedFace(start, area) {
    if (detectionPaused || canceled) return;  // Skip capturing forever if canceled

    // Pause face detection for the capturing animation
    detectionPaused = true;
    newoverlay.classList.add('show');
    void newoverlay.offsetWidth;

    setTimeout(() => {
    if(canceled) return;
        newoverlay.classList.remove('show');
        savebtn_clone.style.display = 'inline-block';
        overlay.appendChild(savebtn_clone);
        overlay.classList.add('show');
        previewcanvas.width = area[0];
        previewcanvas.height = area[1];
        copiedContext.clearRect(0, 0, previewcanvas.width, previewcanvas.height);
        copiedContext.filter = 'contrast(200%)';
        copiedContext.drawImage(
            video,
            start[0], start[1], area[0], area[1],
            0, 0, previewcanvas.width, previewcanvas.height
        );
    }, 3000);
}
let interval = null;
      // Request camera access
        navigator.mediaDevices.getUserMedia({ video: true })
            .then(async (stream) => {
                await loadModel();
                video.srcObject = stream;
                main.style.display = "block";
                video.addEventListener("loadeddata", () => {
                overlaycanvas.width = video.videoWidth;
                overlaycanvas.height = video.videoHeight;
             interval =  setInterval(async () =>{
                overlayContext.clearRect(0, 0, overlaycanvas.width, overlaycanvas.height);
                const liveTensors = false;
                const livePredictions = await model.estimateFaces(video,liveTensors);
                if(livePredictions.length > 0){
                livePredictions.forEach(pred => {
                const start = pred.topLeft;
                const end = pred.bottomRight;
                const area = [end[0] - start[0], end[1] - start[1]];
                overlayContext.strokeStyle = "red";
                overlayContext.lineWidth = 3;
                overlayContext.strokeRect(start[0], start[1], area[0], area[1]);
                if(!canceled&&!detectionPaused){
                showCapturedFace(start,area);
                }
                });
                }
                },100);
                });
            })
            .catch(err => {
                console.error('Error accessing camera:', err);
                alert('Please allow camera access!');

            });

        capturebtn.addEventListener("click",async () => {
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
          const tensors = false;
          const prediction = await model.estimateFaces(canvas,tensors);
          if(prediction.length > 0){
            alert("a face was detected");
          }
          else{
            alert("no face detected");
          }
            savebtn.style.display = "inline-block";
        });
        clearbtn.addEventListener("click",() => {
           context.clearRect( 0, 0, canvas.width, canvas.height);
          savebtn.style.display = "none";
        });
        savebtn.addEventListener("click", async () => {
        await matchFaces(canvas);
        });
         savebtn_clone.addEventListener("click",async () => {
         await matchFaces(previewcanvas);
        });
      canvas.addEventListener("click", () => {
          overlay.classList.add('show');
          copiedContext.drawImage(canvas,0,0,previewcanvas.width, previewcanvas.height);
      });
      closebtn.addEventListener("click", () => {
         overlay.classList.remove('show');
         savebtn_clone.style.display = 'none';
         detectionPaused = false;
      });
      cancelbtn.addEventListener("click", () => {
      newoverlay.classList.remove('show');
      canceled = true;
        capturebtn.style.display = "inline-block";
        clearbtn.style.display = "inline-block";
        picdiv.style.display = "inline-block";
      clearInterval(interval1);
      });
    </script>
</body>
</html>
